import os
import torch
import torch.nn as nn
from tqdm import tqdm
import logging
import matplotlib.pyplot as plt
import matplotlib
# ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç’°å¢ƒï¼ˆã‚µãƒ¼ãƒãƒ¼ç­‰ï¼‰ã§ã®ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼é˜²æ­¢
matplotlib.use('Agg')

logger = logging.getLogger(__name__)

# ===============================
# 1. LRFinder (ãƒ¡ãƒ¢ãƒªç¯€ç´„ç‰ˆ)
# ===============================
class LRFinder:
    """æœ€é©ãªå­¦ç¿’ç‡ã‚’è‡ªå‹•æ¢ç´¢ (CPUãƒ¡ãƒ¢ãƒªã«é…æ…®)"""
    def __init__(self, model, optimizer, device):
        self.model = model
        self.optimizer = optimizer
        self.device = device
        self.history = {'lr': [], 'loss': []}
        
    def find(self, train_loader, min_lr=1e-7, max_lr=1, num_iter=100, smooth_f=0.05):
        logger.info(f"ğŸ” LR Finder: Searching ({min_lr} to {max_lr})...")
        
        # âš ï¸ deepcopyã‚’é¿ã‘ã€é‡ã¿ã ã‘ã‚’CPUã«ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¦ä¿å­˜ (ãƒ¡ãƒ¢ãƒªç¯€ç´„)
        original_weights = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}
        original_opt_state = {k: v for k, v in self.optimizer.state_dict().items()}
        
        mult = (max_lr / min_lr) ** (1 / num_iter)
        lr = min_lr
        self.optimizer.param_groups[0]['lr'] = lr
        
        avg_loss = 0.0
        best_loss = float('inf')
        
        self.model.train()
        iterator = iter(train_loader)
        
        for i in range(num_iter):
            try:
                batch = next(iterator)
            except StopIteration:
                iterator = iter(train_loader)
                batch = next(iterator)
            
            self.optimizer.zero_grad()
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            labels = batch['labels'].to(self.device)
            
            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            
            # æå¤±ã®å¹³æ»‘åŒ–
            avg_loss = smooth_f * loss.item() + (1 - smooth_f) * avg_loss if i > 0 else loss.item()
            
            if avg_loss < best_loss: best_loss = avg_loss
            if i > 1 and avg_loss > 4 * best_loss:
                logger.warning("âš ï¸ Loss diverged, stopping LR finder.")
                break
                
            self.history['lr'].append(lr)
            self.history['loss'].append(avg_loss)
            
            loss.backward()
            self.optimizer.step()
            
            lr *= mult
            for pg in self.optimizer.param_groups: pg['lr'] = lr
            
        # çŠ¶æ…‹ã®å¾©å…ƒ
        self.model.load_state_dict(original_weights)
        self.optimizer.load_state_dict(original_opt_state)
        
        suggested_lr = self.history['lr'][self.history['loss'].index(min(self.history['loss']))] // 10
        logger.info(f"âœ… Suggested LR: {suggested_lr:.2e}")
        return suggested_lr

    def plot(self, save_path):
        plt.figure(figsize=(10, 6))
        plt.plot(self.history['lr'], self.history['loss'])
        plt.xscale('log')
        plt.xlabel('Learning Rate')
        plt.ylabel('Loss')
        plt.grid(True)
        plt.savefig(save_path)
        plt.close()

# ===============================
# 2. å­¦ç¿’è£œåŠ©
# ===============================
class EarlyStopping:
    def __init__(self, patience=2):
        self.patience = patience
        self.counter = 0
        self.best_loss = float('inf')
        self.early_stop = False

    def __call__(self, val_loss):
        if val_loss < self.best_loss:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience: self.early_stop = True

def get_total_steps(phase_epochs, loaders_map, config):
    """å…¨ãƒ•ã‚§ãƒ¼ã‚ºã®ç·æ›´æ–°ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’æ­£ç¢ºã«è¨ˆç®—"""
    total_updates = 0
    
    for phase_idx, n_epochs in enumerate(phase_epochs):
        if n_epochs <= 0: continue
        
        # ãƒ•ã‚§ãƒ¼ã‚ºã”ã¨ã®ãƒ­ãƒ¼ãƒ€ãƒ¼æ§‹æˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        if phase_idx == 0:
            loaders = [loaders_map["span"], loaders_map["bywork"], loaders_map["chunk"]]
        elif phase_idx == 1:
            loaders = [loaders_map["chunk"], loaders_map["bywork"], loaders_map["span"]]
        else:
            # Phase 3: ã‚¢ãƒ³ã‚«ãƒ¼(span)ã‚’æ··ãœã‚‹
            loaders = [loaders_map["practical_chunk"], loaders_map["practical_line"], loaders_map["span"]]
            
        phase_steps = sum(len(l) for l in loaders if l is not None)
        total_updates += (phase_steps // config.accumulation_steps) * n_epochs
        
    return total_updates

# ===============================
# 3. å­¦ç¿’ã‚³ã‚¢
# ===============================
def train_epoch(model, loaders, optimizer, scheduler, scaler, device, config, epoch, criterion=None, ema=None):
    model.train()
    total_loss = 0
    update_count = 0
    
    # è¤‡æ•°ã®ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’é †ç•ªã«å›ã™
    for loader in loaders:
        if loader is None: continue
        pbar = tqdm(loader, desc=f"Epoch {epoch+1}")
        
        for batch_idx, batch in enumerate(pbar):
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["labels"].to(device)

            with torch.amp.autocast(device_type=device.type, enabled=config.use_amp):
                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
                loss = (criterion(outputs.logits, labels) if criterion else outputs.loss) / config.accumulation_steps

            if scaler:
                scaler.scale(loss).backward()
            else:
                loss.backward()

            if (batch_idx + 1) % config.accumulation_steps == 0:
                if scaler:
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)
                    optimizer.step()
                
                optimizer.zero_grad(set_to_none=True)
                if ema: ema.update()
                if scheduler: scheduler.step()
                update_count += 1

            total_loss += loss.item() * config.accumulation_steps
            pbar.set_postfix(lr=f"{optimizer.param_groups[0]['lr']:.1e}", loss=f"{loss.item()*config.accumulation_steps:.4f}")

    return total_loss / update_count if update_count > 0 else total_loss


# trainer.py ã«è¿½åŠ 

def evaluate_model(model, val_loader, device, config, criterion=None, ema=None):
    """æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®æå¤±ã‚’è¨ˆç®—"""
    model.eval()
    if ema: ema.apply_shadow() # EMAã‚’é©ç”¨ã—ã¦è©•ä¾¡
    
    total_loss = 0
    # è©•ä¾¡æ™‚ã¯å‹¾é…è¨ˆç®—ã‚’ã‚ªãƒ•ã«ã—ã¦ãƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„
    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["labels"].to(device)
            
            # CPU/GPU è­¦å‘Šã‚’å›é¿ã—ãŸ autocast
            with torch.amp.autocast(device_type=device.type, enabled=config.use_amp and device.type == 'cuda'):
                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
                loss = (criterion(outputs.logits, labels) if criterion else outputs.loss)
            
            total_loss += loss.item()
            
    if ema: ema.restore() # å­¦ç¿’ç”¨ã«é‡ã¿ã‚’æˆ»ã™
    model.train()
    return total_loss / len(val_loader) if len(val_loader) > 0 else 0